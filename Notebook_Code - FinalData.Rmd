---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
---

This is the mark-up file for the Datenanalyse 2 homework assignment.


```{r}
library("rio")
x <- import("https://docs.google.com/spreadsheets/d/1h7XhLd2Byp4OcXSdtxHly9iS7RA673RJ/export?format=csv&gid=1083477596")

str(x)

x$commentCount <- as.integer(x$commentCount)
x$viewsCount <- as.numeric(x$viewsCount)
x$acousticness <- as.numeric(sub(",", ".", x$acousticness, fixed = TRUE))
x$danceability <- as.numeric(sub(",", ".", x$danceability, fixed = TRUE))
x$energy <- as.numeric(sub(",", ".", x$energy, fixed = TRUE))
x$instrumentalness <- as.numeric(sub(",", ".", x$instrumentalness, fixed = TRUE))
x$liveness <- as.numeric(sub(",", ".", x$liveness, fixed = TRUE))
x$loudness <- as.numeric(sub(",", ".", x$loudness, fixed = TRUE))
x$speechiness <- as.numeric(sub(",", ".", x$speechiness, fixed = TRUE))
x$tempo <- as.numeric(sub(",", ".", x$tempo, fixed = TRUE))
x$valence <- as.numeric(sub(",", ".", x$valence, fixed = TRUE))

x$key <- as.factor(x$key)
x$time_signature <- as.factor(x$time_signature)


min_max_normalize <- function(x)
{
    return( (1000-10)*((x- min(x)) /(max(x)-min(x))) + 10)
}

x$acousticness <- min_max_normalize(x$acousticness)
x$danceability <- min_max_normalize(x$danceability)
x$energy <- min_max_normalize(x$energy)
x$instrumentalness <- min_max_normalize(x$instrumentalness)
x$liveness <- min_max_normalize(x$liveness)
x$loudness <- min_max_normalize(x$loudness)
x$speechiness <- min_max_normalize(x$speechiness)
x$tempo <- min_max_normalize(x$tempo)
x$valence <- min_max_normalize(x$valence)

```


```{r}
library("dplyr")

drop.cols <- c('Artist_ID', 'Genre', 'Release_Date', 'Track_Artist', 'Track_ID', 'Track_Title', 'video_ID', 'key', 'time_signature')
numeric_x <- select(x, -one_of(drop.cols))

keep.cols <- c('Streams', 'Artist_Follower', 'Track_Duration_ms',
               'viewsCount')

# keep.cols <- c('Streams', 'viewsCount', 'Title_Youtube_searches_11m')

selected_pairs <- select(x, keep.cols)

pairs(selected_pairs, cex=0.5)

```


Descriptive statistics

```{r}

summary(numeric_x)

```


Histograms and kernel density plots of base variables

```{r}

par(mfrow=c(3,3))

hist(x$Artist_Albums_Number, probability = TRUE, col = "gray")
lines(density(x$Artist_Albums_Number), col = "red")

hist(x$Artist_Albums_Tracks_Number, probability = TRUE, col = "gray")
lines(density(x$Artist_Albums_Tracks_Number), col = "red")

hist(x$Artist_Appearances_Number, probability = TRUE, col = "gray")
lines(density(x$Artist_Appearances_Number), col = "red")

hist(x$Artist_Appearances_Tracks_Number, probability = TRUE, col = "gray")
lines(density(x$Artist_Appearances_Tracks_Number), col = "red")

hist(x$Artist_Follower, probability = TRUE, col = "gray")
lines(density(x$Artist_Follower), col = "red")

hist(x$Artist_Popularity, probability = TRUE, col = "gray")
lines(density(x$Artist_Popularity), col = "red")

hist(x$Artist_Singles_Number, probability = TRUE, col = "gray")
lines(density(x$Artist_Singles_Number), col = "red")

hist(x$Artist_Singles_Tracks_Number, probability = TRUE, col = "gray")
lines(density(x$Artist_Singles_Tracks_Number), col = "red")

hist(x$Streams, probability = TRUE, col = "gray")
lines(density(x$Streams, na.rm = TRUE), col = "red")

```

```{r}

par(mfrow=c(3,3))

hist(x$Track_Duration_ms, probability = TRUE, col = "gray")
lines(density(x$Track_Duration_ms), col = "red")

hist(x$Track_Popularity, probability = TRUE, col = "gray")
lines(density(x$Track_Popularity), col = "red")

# hist(x$Title_Artist_Google_searches_11m, probability = TRUE, col = "gray")
# lines(density(x$Title_Artist_Google_searches_11m), col = "red")

# hist(x$Title_Artist_Youtube_searches_11m, probability = TRUE, col = "gray")
# lines(density(x$Title_Artist_Youtube_searches_11m), col = "red")

# hist(x$Title_Google_searches_11m, probability = TRUE, col = "gray")
# lines(density(x$Title_Google_searches_11m), col = "red")

# hist(x$Total_tracks, probability = TRUE, col = "gray")
# lines(density(x$Total_tracks), col = "red")

# hist(x$Artist_Google_searches_11m, probability = TRUE, col = "gray")
# lines(density(x$Artist_Google_searches_11m), col = "red")

# hist(x$Artist_Youtube_searches_11m, probability = TRUE, col = "gray")
# lines(density(x$Artist_Youtube_searches_11m), col = "red")

hist(x$commentCount, probability = TRUE, col = "gray")
lines(density(x$commentCount, na.rm = TRUE), col = "red")

```

```{r}
par(mfrow=c(3,3))

hist(x$dislikeCount, probability = TRUE, col = "gray")
lines(density(x$dislikeCount, na.rm = TRUE), col = "red")

hist(log(x$viewsCount), probability = TRUE, col = "gray")
lines(density(log(x$viewsCount), na.rm = TRUE), col = "red")

hist(x$acousticness, probability = TRUE, col = "gray")
lines(density(x$acousticness), col = "red")

hist(x$danceability, probability = TRUE, col = "gray")
lines(density(x$danceability), col = "red")

hist(x$energy, probability = TRUE, col = "gray")
lines(density(x$energy), col = "red")

hist(x$instrumentalness, probability = TRUE, col = "gray")
lines(density(x$instrumentalness), col = "red")

hist(x$liveness, probability = TRUE, col = "gray")
lines(density(x$liveness), col = "red")

hist(x$loudness, probability = TRUE, col = "gray")
lines(density(x$loudness), col = "red")

hist(x$speechiness, probability = TRUE, col = "gray")
lines(density(x$speechiness), col = "red")


```

```{r}

par(mfrow=c(1,2))

hist(x$tempo, probability = TRUE, col = "gray")
lines(density(x$tempo), col = "red")

hist(x$valence, probability = TRUE, col = "gray")
lines(density(x$valence), col = "red")

```



Distribution testing

1) Normality

```{r}

strictly_positive_variables <- c('Artist_Follower', 'Artist_Popularity', 'Streams', 'Track_Duration_ms', 'viewsCount', 'acousticness', 'danceability', 'energy', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence')


summary(select(x, strictly_positive_variables))


for (i in 1:length(strictly_positive_variables)){
  
  column_name <- strictly_positive_variables[i]
  
  message(column_name)
  
  sub_df <- numeric_x[column_name]
  
  sub_df <- sub_df[complete.cases(sub_df), ]
  
  #sub_df <- as.numeric(as.character(unlist(sub_df[[1]])))
  
  test_statistic <- ks.test(sub_df, "pnorm", mean=mean(sub_df), sd=sd(sub_df))$statistic
  critical_value <- 1.3581 / sqrt (length(sub_df))
  
  if (test_statistic > critical_value) {
message(paste(" ", column_name , " is not approximately normally distributed.", test_statistic, critical_value))
} else {
message(paste(" ", column_name , " is approximately normally distributed!", test_statistic, critical_value))  
}}


```

None of the strictly positive variables in their base specification passes the KS test.


2) Standard normality

```{r}


numeric_x_scaled <- scale(numeric_x, center = TRUE, scale = TRUE)
numeric_x_scaled <- as.data.frame(numeric_x_scaled)

par(mfrow=c(3,3))

hist(numeric_x_scaled$Artist_Albums_Number, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Artist_Albums_Number), col = "red")

hist(numeric_x_scaled$Artist_Albums_Tracks_Number, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Artist_Albums_Tracks_Number), col = "red")

hist(numeric_x_scaled$Artist_Appearances_Number, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Artist_Appearances_Number), col = "red")

hist(numeric_x_scaled$Artist_Appearances_Tracks_Number, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Artist_Appearances_Tracks_Number), col = "red")

hist(numeric_x_scaled$Artist_Follower, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Artist_Follower), col = "red")

hist(numeric_x_scaled$Artist_Popularity, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Artist_Popularity), col = "red")

hist(numeric_x_scaled$Artist_Singles_Number, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Artist_Singles_Number), col = "red")

hist(numeric_x_scaled$Artist_Singles_Tracks_Number, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Artist_Singles_Tracks_Number), col = "red")

hist(numeric_x_scaled$Streams, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Streams, na.rm = TRUE), col = "red")

```

```{r}

par(mfrow=c(3,3))

hist(numeric_x_scaled$Track_Duration_ms, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Track_Duration_ms), col = "red")

hist(numeric_x_scaled$Track_Popularity, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$Track_Popularity), col = "red")

# hist(numeric_x_scaled$Title_Artist_Google_searches_11m, probability = TRUE, col = "gray")
# lines(density(numeric_x_scaled$Title_Artist_Google_searches_11m), col = "red")

# hist(numeric_x_scaled$Title_Artist_Youtube_searches_11m, probability = TRUE, col = "gray")
# lines(density(numeric_x_scaled$Title_Artist_Youtube_searches_11m), col = "red")

# hist(numeric_x_scaled$Title_Google_searches_11m, probability = TRUE, col = "gray")
# lines(density(numeric_x_scaled$Title_Google_searches_11m), col = "red")

# hist(numeric_x_scaled$Total_tracks, probability = TRUE, col = "gray")
# lines(density(numeric_x_scaled$Total_tracks), col = "red")

#hist(numeric_x_scaled$Artist_Google_searches_11m, probability = TRUE, col = "gray")
#lines(density(numeric_x_scaled$Artist_Google_searches_11m), col = "red")

#hist(numeric_x_scaled$Artist_Youtube_searches_11m, probability = TRUE, col = "gray")
#lines(density(numeric_x_scaled$Artist_Youtube_searches_11m), col = "red")

hist(numeric_x_scaled$commentCount, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$commentCount, na.rm = TRUE), col = "red")
```

```{r}
par(mfrow=c(1,2))

hist(numeric_x_scaled$dislikeCount, probability = TRUE, col = "gray")
lines(density(numeric_x_scaled$dislikeCount, na.rm = TRUE), col = "red")

hist(log(x$viewsCount), probability = TRUE, col = "gray")
lines(density(log(x$viewsCount)), col = "red")

```

```{r}

for (i in 1:length(strictly_positive_variables)){
  
  column_name <- strictly_positive_variables[i]
  
  sub_df <- numeric_x_scaled[column_name]
  sub_df <- sub_df[complete.cases(sub_df), ]
  
  # sub_df <- as.numeric(as.character(unlist(sub_df[[1]])))
  
  test_statistic <- ks.test(sub_df, "pnorm", mean=mean(sub_df), sd=sd(sub_df))$statistic
  critical_value <- 1.3581 / sqrt (length(sub_df))
  
  if (test_statistic > critical_value) {
message(paste(" Z-transformed ", column_name , " is not approximately normally distributed.", test_statistic, critical_value))
} else {
message(paste(" Z-transformed ", column_name , " is approximately normally distributed!", test_statistic, critical_value))  
}}



```

Again, none of the z-transformed variables is approximately normally distributed, however only Track_Duration_ms is close to the critical value at $\alpha$ = 0.05.

3) Log-normality

```{r}

log_numeric_x <- log(numeric_x)

par(mfrow=c(3,3))

hist(log_numeric_x$Artist_Albums_Number, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Artist_Albums_Number), col = "red")

hist(log_numeric_x$Artist_Albums_Tracks_Number, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Artist_Albums_Tracks_Number), col = "red")

hist(log_numeric_x$Artist_Appearances_Number, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Artist_Appearances_Number), col = "red")

hist(log_numeric_x$Artist_Appearances_Tracks_Number, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Artist_Appearances_Tracks_Number), col = "red")

hist(log_numeric_x$Artist_Follower, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Artist_Follower), col = "red")

hist(log_numeric_x$Artist_Popularity, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Artist_Popularity), col = "red")

hist(log_numeric_x$Artist_Singles_Number, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Artist_Singles_Number), col = "red")

hist(log_numeric_x$Artist_Singles_Tracks_Number, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Artist_Singles_Tracks_Number), col = "red")

hist(log_numeric_x$Streams, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Streams, na.rm = TRUE), col = "red")

```

```{r}

par(mfrow=c(3,3))

hist(log_numeric_x$Track_Duration_ms, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Track_Duration_ms), col = "red")

hist(log_numeric_x$Track_Popularity, probability = TRUE, col = "gray")
lines(density(log_numeric_x$Track_Popularity), col = "red")

#hist(log_numeric_x$Title_Artist_Google_searches_11m, probability = TRUE, col = "gray")
#lines(density(log_numeric_x$Title_Artist_Google_searches_11m), col = "red")

#hist(log_numeric_x$Title_Artist_Youtube_searches_11m, probability = TRUE, col = "gray")
#lines(density(log_numeric_x$Title_Artist_Youtube_searches_11m), col = "red")

#hist(log_numeric_x$Title_Google_searches_11m, probability = TRUE, col = "gray")
#lines(density(log_numeric_x$Title_Google_searches_11m), col = "red")

#hist(log_numeric_x$Total_tracks, probability = TRUE, col = "gray")
#lines(density(log_numeric_x$Total_tracks), col = "red")

#hist(log_numeric_x$Artist_Google_searches_11m, probability = TRUE, col = "gray")
#lines(density(log_numeric_x$Artist_Google_searches_11m), col = "red")

#hist(log_numeric_x$Artist_Youtube_searches_11m, probability = TRUE, col = "gray")
#lines(density(log_numeric_x$Artist_Youtube_searches_11m), col = "red")

hist(log_numeric_x$commentCount, probability = TRUE, col = "gray")
lines(density(log_numeric_x$commentCount, na.rm = TRUE), col = "red")

```


```{r}
par(mfrow=c(1,2))

hist(log_numeric_x$dislikeCount, probability = TRUE, col = "gray")
lines(density(log_numeric_x$dislikeCount, na.rm = TRUE), col = "red")

hist(log_numeric_x$viewsCount, probability = TRUE, col = "gray")
lines(density(log_numeric_x$viewsCount), col = "red")

```


```{r}

for (i in 1:length(strictly_positive_variables)){
  
  column_name <- strictly_positive_variables[i]
  
  sub_df <- numeric_x[column_name]
  sub_df <- sub_df[complete.cases(sub_df), ]
  sub_df <- sub_df[sub_df > 1]
  sub_df <- log(sub_df)
  # sub_df <- as.numeric(as.character(unlist(sub_df[[1]])))
  
  test_statistic <- ks.test(sub_df, "pnorm", mean=mean(sub_df), sd=sd(sub_df))$statistic
  critical_value <- 1.3581 / sqrt (length(sub_df))
  
  if (test_statistic > critical_value) {
message(paste(" Log-transformed ", column_name , " is not approximately normally distributed.", test_statistic, critical_value))
} else {
message(paste(" Log-ransformed ", column_name , " is approximately normally distributed!", test_statistic, critical_value))  
}}


```

After log-transforming the variables, streams and viewsCount are approximately normally distributed, so we can proceed with testing whether they are also jointly (log-) normally distributed.

$H_0$: two variables are jointly normal distributed 
$H_1$: two variables are not jointly normal distributed

```{r}

plot(log(x$viewsCount), log(x$Streams))

bivariate_df <- select(log_numeric_x, c('Streams', 'viewsCount'))

# install.packages("MVN")

library("MVN")

mvn(bivariate_df, mvnTest = "mardia")$multivariateNormality # Not jointly normal
mvn(bivariate_df, mvnTest = "hz")$multivariateNormality # Not jointly normal
mvn(bivariate_df, mvnTest = "royston")$multivariateNormality # 
mvn(bivariate_df, mvnTest = "energy")$multivariateNormality

```

Result: all tests reject the Null hypothesis that the two variables log-Streams and log-viewsCount are jointly normally distributed. Hence, Steiger's Z test cannot be meaningfully conducted. All results displayed in the correlogram are thefore to be treated with caution.


4) Box-Cox transformations


```{r}

library("psych")
library("car")

ksD <- function (p, x) {
  y <- bcPower(x, p)
  ks.test(y, "pnorm", mean=mean(y), sd=sd(y))$statistic
}

oldw <- getOption("warn")
options(warn = -1)

min_values <- c()

for (column_index in 1:length(strictly_positive_variables)){
  
  column_name <- strictly_positive_variables[column_index]
  
  x_sub <- as.numeric(x[[paste(column_name)]])
  
  x_sub <- x_sub[complete.cases(x_sub)]
  
  result <- optimize(ksD, c(-5,5), x=x_sub)
  
  min_values[column_index] <- result$minimum
  
  message(paste(column_index, ', minimum value is: ', result$minimum))
  
}

options(warn = oldw)

```

Box-Cox transformations

```{r}

par(mfrow=c(2,5))

column_index <- 1
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
Artist_Follower_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 2
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
Artist_Popularity_trans <- bcPower(x_sub, min_values[column_index])

#column_index <- 3
#column_name <- strictly_positive_variables[column_index]
#x_sub <- as.numeric(x[[paste(column_name)]])
#Artist_Singles_Number_trans <- bcPower(x_sub, min_values[column_index])

#column_index <- 4
#column_name <- strictly_positive_variables[column_index]
#x_sub <- as.numeric(x[[paste(column_name)]])
#Artist_Singles_Tracks_Number_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 3
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
Streams_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 4
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
Track_Duration_ms_trans <- bcPower(x_sub, min_values[column_index])

#column_index <- 7
#column_name <- strictly_positive_variables[column_index]
#x_sub <- as.numeric(x[[paste(column_name)]])
#Total_tracks_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 5
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
viewsCount_trans <- bcPower(x_sub, min_values[column_index])

#column_index <- 9
#column_name <- strictly_positive_variables[column_index]
#x_sub <- as.numeric(x[[paste(column_name)]])
#Artist_Google_searches_11m_trans <- bcPower(x_sub, min_values[column_index])

#column_index <- 10
#column_name <- strictly_positive_variables[column_index]
#x_sub <- as.numeric(x[[paste(column_name)]])
#Artist_Youtube_searches_11m_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 6
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
acousticness_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 7
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
danceability_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 8
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
energy_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 9
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
liveness_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 10
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
loudness_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 11
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
speechiness_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 12
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
tempo_trans <- bcPower(x_sub, min_values[column_index])

column_index <- 13
column_name <- strictly_positive_variables[column_index]
x_sub <- as.numeric(x[[paste(column_name)]])
x_sub <- x_sub[complete.cases(x_sub)]
valence_trans <- bcPower(x_sub, min_values[column_index])

hist_trans_list <- list(Artist_Follower_trans, Artist_Popularity_trans, Streams_trans, Track_Duration_ms_trans,
                     viewsCount_trans, acousticness_trans, danceability_trans, energy_trans, liveness_trans, 
                     loudness_trans, speechiness_trans, tempo_trans, valence_trans)

for (trans_index in 1:length(hist_trans_list)){
  
  column_name <- strictly_positive_variables[trans_index]
  
  message(column_name)
  
  selected_trans <- hist_trans_list[trans_index]
  selected_trans <- as.numeric(as.character(unlist(selected_trans[[1]])))
  
  hist(selected_trans, col = "gray", probability = TRUE, main = "Histogram of Box-Cox transformed", xlab = column_name)
  points(seq(min(selected_trans), max(selected_trans), length.out = 500),
       dnorm(seq(min(selected_trans), max(selected_trans), length.out = 500),
             mean(selected_trans),sd(selected_trans)), type = "l", col = "red")
  
  test_statistic <- ks.test(selected_trans, "pnorm", mean=mean(selected_trans), sd=sd(selected_trans))$statistic
  critical_value <- 1.3581 / sqrt (length(selected_trans))
  
  if (test_statistic > critical_value) {
message(paste("Transformed ", column_name , " is not approximately normally distributed.", test_statistic, critical_value))
} else {
message(paste("Transformed ", column_name , " is approximately normally distributed!", test_statistic, critical_value))  
}}




#test_statistic <- ks.test(Artist_Follower_trans, "pnorm", mean=mean(Artist_Follower_trans), sd=sd(Artist_Follower_trans))$statistic
#critical_value <- 1.3581 / sqrt (length(x_sub))

#if (test_statistic > critical_value) {
#message(paste("Transformed ", column_name , " is not approximately normally distributed.", test_statistic, critical_value))
#} else {
#message(paste("Transformed ", column_name , " is approximately normally distributed!", test_statistic, critical_value))  
#}



```


Again, after Box-Cox transforming the variables with $\lambda$ equal to the optimized, minimum value to pass the KS test only viewsCount appears to be approximately normally distributed. Similarly, Streams is close to passing the KS test and therefore I'll also test for joint normality using the optimally Box-Cox-transformed variables.


```{r}

plot(viewsCount_trans, Streams_trans)

bivariate_df <- data.frame(viewsCount_trans, Streams_trans)

mvn(bivariate_df, mvnTest = "mardia")$multivariateNormality # Not jointly normal
mvn(bivariate_df, mvnTest = "hz")$multivariateNormality # Not jointly normal
mvn(bivariate_df, mvnTest = "royston")$multivariateNormality # 
mvn(bivariate_df, mvnTest = "energy")$multivariateNormality


```

Result: all tests reject the Null hypothesis that the two variables optimal Box-Cox-Streams and optimal Box-Cox-viewsCount are jointly normally distributed. 


Table by genre

```{r}

table(x$Genre)

```



```{r}

##1

col <- ifelse(x$Genre == "Techno", "black", "red")

plot(x$viewsCount, x$Track_Popularity, main="Track Popularity", pch=19, col=col)

plot(log(x$viewsCount), log(x$Track_Popularity), main="Track Popularity", pch=19, col=col)


```

```{r}

library("lattice")
xyplot(Track_Popularity~viewsCount|Genre, data=x, pch=19)
xyplot(log_numeric_x$Track_Popularity~log_numeric_x$viewsCount|x$Genre, pch=19)

```

```{r}

library("ggplot2")

d <-ggplot(x, aes(x=as.integer(viewsCount), y=as.integer(Track_Popularity), colour=Genre))
d + geom_point(shape=19)

d <-ggplot(x, aes(x=log(viewsCount), y=log(Track_Popularity), colour=Genre))
d + geom_point(shape=19)

```

Using sunflower plot to overcome problem of overplotting.

```{r}

sunflower_viewsCount <- 2*round(x$viewsCount/2)
sunflower_streams  <- 2*round(x$Track_Popularity/2)
sunflowerplot(sunflower_streams~sunflower_viewsCount)

```

```{r}
library("Rmpfr")

# (one <- mpfr(1, 120))

cor <- cor(numeric_x)
drop.cor_cols <- c('Artist_Compilations_Number', 'Artist_Compilations_Tracks_Number', 'Streams')
numeric_cor_x <- select(numeric_x, -one_of(drop.cor_cols))

numeric_cor_x$viewsCount <- as.numeric(numeric_cor_x$viewsCount)

str(numeric_cor_x)

clean_cor <- cor(numeric_cor_x[complete.cases(numeric_cor_x), ])
heatmap(clean_cor, revC=T, col=topo.colors(10))

```

```{r}
library("lattice")
levelplot(clean_cor, scales=list(x=list(rot=90)), aspect = "fill", col.regions=heat.colors(100))


```

```{r}
library("gplots")
gplots::heatmap.2(clean_cor, revC=T, na.rm=T)

```

Tests for significance of Bravais-Pearson, Spearman and Kendall correlation coefficients 

```{r}

x$stream_quantile_ind <- 0

stream_quantiles <- quantile(x$Track_Popularity, probs = c(0.25, 0.5, 0.75))

streams_q_25 <- stream_quantiles[1]
streams_median <- stream_quantiles[2]
streams_q_75 <- stream_quantiles[3]

x$stream_quantile_ind <- ifelse(x$Track_Popularity < streams_q_25, 1, x$stream_quantile_ind + 0)
x$stream_quantile_ind <- ifelse(((x$Track_Popularity >= streams_q_25) & (x$Track_Popularity < streams_median)), 2, x$stream_quantile_ind + 0)
x$stream_quantile_ind <- ifelse(((x$Track_Popularity >= streams_median) & (x$Track_Popularity < streams_q_75)), 3, x$stream_quantile_ind + 0)
x$stream_quantile_ind <- ifelse((x$Track_Popularity >= streams_q_75), 4, x$stream_quantile_ind + 0)

# bottom_25 <- subset(x , Streams < q_25)
# top_50_75 <- subset(x, Streams >= q_25 & Streams < median)
# top_25_50 <- subset(x , Streams >= median & Streams < q_75)
# top_25 <- subset(x, Streams >= q_75)

x$stream_quantile_ind <- as.factor(x$stream_quantile_ind)
x$Genre <- as.factor(x$Genre)

tab<-table(x$Genre, x$stream_quantile_ind)
tab

# critical Chi^2 value (df= 27): 40.11

chisq.test(tab)
chisq.test(tab, simulate.p.value = TRUE)

library("vcd")
assocstats(tab)

```

The p-value is smaller than the confidence level $\alpha$ = 0.05, hence we reject the Null hypothesis of no independence and conclude that there exists a dependence between the songs' genre and their placement within the four quantile ranges of the distribution of their amount of streams.
Cramer's V (~0.16) suggests that there is a weak dependence between the ranking of a track and its genre.


```{r}

x$viewsCount_quantile_ind <- 0

viewsCount_quantiles <- quantile(x$viewsCount, probs = c(0.25, 0.5, 0.75))

viewsCount_q_25 <- viewsCount_quantiles[1]
viewsCount_median <- viewsCount_quantiles[2]
viewsCount_q_75 <- viewsCount_quantiles[3]

x$viewsCount_quantile_ind <- ifelse(x$viewsCount < viewsCount_q_25, 1, x$viewsCount_quantile_ind + 0)
x$viewsCount_quantile_ind <- ifelse(((x$viewsCount >= viewsCount_q_25) & (x$viewsCount < viewsCount_median)), 2, x$viewsCount_quantile_ind + 0)
x$viewsCount_quantile_ind <- ifelse(((x$viewsCount >= viewsCount_median) & (x$viewsCount < viewsCount_q_75)), 3, x$viewsCount_quantile_ind + 0)
x$viewsCount_quantile_ind <- ifelse((x$viewsCount >= viewsCount_q_75), 4, x$viewsCount_quantile_ind + 0)

# bottom_25 <- subset(x , Streams < q_25)
# top_50_75 <- subset(x, Streams >= q_25 & Streams < median)
# top_25_50 <- subset(x , Streams >= median & Streams < q_75)
# top_25 <- subset(x, Streams >= q_75)

x$viewsCount_quantile_ind <- as.factor(x$viewsCount_quantile_ind)

tab<-table(x$Genre, x$viewsCount_quantile_ind)
tab

# critical Chi^2 value (df= 27): 40.11

chisq.test(tab)
chisq.test(tab, simulate.p.value = TRUE)

library("vcd")
assocstats(tab)

```

The p-value is smaller than the confidence level $\alpha$ = 0.05, hence we reject the Null hypothesis of no independence and conclude that there exists a dependence between the songs' genre and their placement within the four quantile ranges of the distribution of their views on Youtube.
Cramer's V (~0.3) suggests that there is a semi-weak dependence between the ranking of a music video and its genre.


```{r}

x$Follower_median_ind <- 0

Follower_median <- median(x$Artist_Follower)

x$Follower_median_ind <- ifelse(x$Artist_Follower < Follower_median, 0, 1)
x$Follower_median_ind <- as.factor(x$Follower_median_ind)

tab<-table(x$Genre, x$Follower_median_ind)
tab

# critical Chi^2 value (df= 27): 40.11

chisq.test(tab)
chisq.test(tab, simulate.p.value = TRUE)
assocstats(tab)

# kendall's tau for stream quantile and follower median

ab2 <- na.omit(cbind(x$stream_quantile_ind, x$Follower_median_ind))

library("ryouready")
ord.tau(table(ab2[,1], ab2[,2]))

cor(as.numeric(x$stream_quantile_ind), as.numeric(x$Follower_median_ind), method = "kendall") # identical result

cor.test(as.numeric(x$stream_quantile_ind), as.numeric(x$Follower_median_ind), method="kendall")



```

The relationship between genre and whether the track's artist's follower count is smaller than the median value (=0) or not (=1) appears to be significant and semi-weak, as suggested by the $\chi^2$-Test and Cramer's V.

The relationship between stream quantiles and the follower > median indicator variable appears to be negative (about -0.09) and is significant at the $\alpha$ = 0.01 level. 

Let's see whether there exists an ordinal relationship between the placement of streams within the distributional range and the placement of the corresponding music video's views: 

```{r}

ab2 <- na.omit(cbind(x$stream_quantile_ind, x$viewsCount_quantile_ind))
nrow(ab2)*(nrow(ab2)-1)/2
#
ind <- order(ab2[,1], ab2[,2])
ab2 <- ab2[ind,]
#b
C <- D <- Tx <- Ty <- Txy <- 0
for (i in 1:(nrow(ab2)-1)) {
  if (i%%100==0) cat(i, "\n")
  for(j in (i+1):nrow(ab2)) {
    if (ab2[i,1]==ab2[j,1]) {
      if (ab2[i,2]==ab2[j,2]) {
        Txy <- Txy+1
      } else {
        Tx <- Tx+(ab2[i,2]<ab2[j,2])
      }
    } else {   
      if (ab2[i,2]==ab2[j,2]) Ty <- Ty+1
      if (ab2[i,2]<ab2[j,2]) C <- C+1
      if (ab2[i,2]>ab2[j,2]) D <- D+1
    }
  }
}

c(C=C, D=D, Tx=Tx, Ty=Ty, Txy=Txy)

k_t <- (C - D)/(nrow(ab2)*(nrow(ab2)-1)/2)
k_t # (without ties)

library("ryouready")
ord.tau(table(ab2[,1], ab2[,2]))

cor(as.numeric(x$stream_quantile_ind), as.numeric(x$viewsCount_quantile_ind), method = "kendall") # identical result

cor.test(as.numeric(x$stream_quantile_ind), as.numeric(x$viewsCount_quantile_ind), method="kendall")

tab<-table(x$stream_quantile_ind, x$viewsCount_quantile_ind)
chisq.test(tab)
chisq.test(tab, simulate.p.value = TRUE)

library("vcd")
assocstats(tab)

```

The rank correlation coefficient by Kendall's Tau (here for a quadratic table) is around 0.41 and the test yields that this coefficient is significant, hence we can conclude that there exists a positive relationship between the placement of streams of a song on Spotify and the placement of views of the corresponding music video on Youtube, meaning a higher rank of the song's music video in Youtube views is associated with a higher rank inside of Spotify's streams.

Even if not appropriate since the two variables have an ordinal scale and using $\chi^2$ test for independence would neglect additional information, Cramer's V (~0.33) states there exists a semi-weak relationship but without inferring anything about the direction of the relationship, only the strength of this relationship. Therefore, Kendall's Tau gives us the appropriate estimate, indicating the positive relationship between the two ordinal variables.

```{r}

numeric_cor_x$stream_quantile_ind <- as.numeric(x$stream_quantile_ind)
numeric_cor_x$viewsCount_quantile_ind <- as.numeric(x$viewsCount_quantile_ind)
numeric_cor_x$Follower_median_ind <- as.numeric(x$Follower_median_ind)

clean_cor <- cor(numeric_cor_x[complete.cases(numeric_cor_x), ])

library(corrplot)

corrplot(clean_cor, method="circle")

cor.mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat<- matrix(NA, n, n)
  diag(p.mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], ..., method = "kendall")
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
    }
  }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

# matrix of the p-value of the correlation
p.mat <- cor.mtest(clean_cor)

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
significance_level <- 0.05

corrplot(clean_cor, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=90, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = significance_level, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE)


```


![Correlogram with significant Spearman correlation coefficients at $\alpha$ = 0.05](images/Spearman_5.png)

Prediction Reduction Error measures

Goodmann and Kruskals $\lambda$

1) predicting stream quantile without any knowledge about association with view quantiles, just taking the mode as predictor

2) predicting stream quantile with knowledge about track's corresponding placement in video view distribution

```{r}

modetab <- function(x, margin=0) { 
  if (margin>0) apply(x, margin, max) else max(x) 
}

tab2 <- table(numeric_cor_x$stream_quantile_ind, 
              numeric_cor_x$viewsCount_quantile_ind, dnn = c("Song streams", "Video views"))

tab2

tab <- rowSums(tab2)

message(paste("The mode is equal across all four quantiles of stream distribution, which is", modetab(tab)))


e1_streams <- sum(tab) - modetab(tab)

message(paste("Without any knowledge about an additional feature other than music streams itself and using the mode across classes as best predictor for class assignment for a new observation, the number of falsely predicted cases would be: ", e1_streams, " or ", e1_streams/sum(tab), "%."))

e2_streams <- sum(tab2) - sum(modetab(tab2, 2))

message(paste("Now having knowledge about an association between track streams and its video views and using class-internal modes for the additional feature, the number of falsely predicted cases would be: ", e2_streams, " or ", e2_streams/sum(tab), "%, which is already much lower compared to the error rate from predicting without any knowledge about an association. On the other hand, ", sum(tab2)-e2_streams, " or ", (sum(tab2)-e2_streams)/sum(tab2), "% would have been predicted correctly (compared to ", 1-e1_streams/sum(tab), "% if there was no knowledge about video views classes.)"))

message("For example, the best prediction for a song that resided within the bottom quantile of video views would be that it also resides inside of the bottom quantile of streams as the mode of 95 was found to be from this class. Hence, using the class mode of the lower bottom quantile video views to predict lower bottom quantile streams would yield 95 correct cases but 180-95= 85 misclassified predictions.")

lambda <- (e1_streams - e2_streams)/e1_streams

message(paste("Therefore, Goodmann and Kruskals Lambda is: ", lambda))

library("ryouready")

nom.lambda(tab2)


```

1) predicting stream quantile without any knowledge about association with genre, just taking the mode as predictor

2) predicting stream quantile with knowledge about track's genre

```{r}

tab2 <- table(numeric_cor_x$stream_quantile_ind, 
              x$Genre, dnn = c("Song streams", "Genre"))

tab2

tab <- rowSums(tab2)

message(paste("The mode is equal across all four quantiles of stream distribution, which is", modetab(tab)))


e1_streams <- sum(tab) - modetab(tab)

message(paste("Without any knowledge about an additional feature other than music streams itself and using the mode across classes as best predictor for class assignment for a new observation, the number of falsely predicted cases would be: ", e1_streams, " or ", e1_streams/sum(tab), "%."))

e2_streams <- sum(tab2) - sum(modetab(tab2, 2))

message(paste("Now having knowledge about an association between track streams and its genre and using class-internal modes for the additional feature, the number of falsely predicted cases would be: ", e2_streams, " or ", e2_streams/sum(tab), "%, which is already much lower compared to the error rate from predicting without any knowledge about an association. On the other hand, ", sum(tab2)-e2_streams, " or ", (sum(tab2)-e2_streams)/sum(tab2), "% would have been predicted correctly (compared to ", 1-e1_streams/sum(tab), "% if there was no knowledge about genre.)"))

message("For example, the best prediction for a song that is from the genre 'Hip-Hop' would be that it resides inside of the 3rd quantile of streams as the mode of 116 was found to be from this class. Hence, using the class mode of the genre 'Hip-Hop' to predict 3rd quantile streams would yield 116 correct cases but 411-116= 295 misclassified predictions.")

lambda <- (e1_streams - e2_streams)/e1_streams

message(paste("Therefore, Goodmann and Kruskals Lambda is: ", lambda))

library("ryouready")

nom.lambda(tab2)



```

For genre and stream quantile association the improvement of using this association rather than the single mode as best predictor for stream quantile is moderate, compared to the improvement in accuracy from predicting stream quantiles with video view quantiles.



1) predicting stream quantile without any knowledge about association with follower > median indicator, just taking the mode as predictor

2) predicting stream quantile with knowledge about follower indicator

```{r}

tab2 <- table(numeric_cor_x$stream_quantile_ind, 
              x$Follower_median_ind, dnn = c("Song streams", "Follower indicator"))

tab2

tab <- rowSums(tab2)

message(paste("The mode is equal across all four quantiles of stream distribution, which is", modetab(tab)))


e1_streams <- sum(tab) - modetab(tab)

message(paste("Without any knowledge about an additional feature other than music streams itself and using the mode across classes as best predictor for class assignment for a new observation, the number of falsely predicted cases would be: ", e1_streams, " or ", e1_streams/sum(tab), "%."))

e2_streams <- sum(tab2) - sum(modetab(tab2, 2))

message(paste("Now having knowledge about an association between track streams and its artist's followers and using class-internal modes for the additional feature, the number of falsely predicted cases would be: ", e2_streams, " or ", e2_streams/sum(tab), "%, which is insignificantly lower compared to the error rate from predicting without any knowledge about an association. On the other hand, ", sum(tab2)-e2_streams, " or ", (sum(tab2)-e2_streams)/sum(tab2), "% would have been predicted correctly (compared to ", 1-e1_streams/sum(tab), "% if there was no knowledge about follower.)"))

message("For example, the best prediction for a song of which artist's follower count is above the median would be that it resides inside of the 1st quantile of streams as the mode of 106 was found to be from this class. Hence, using the class mode of artists' followers above median to predict 1st quantile streams would yield 106 correct cases but 381-106 = 275 misclassified predictions.")

lambda <- (e1_streams - e2_streams)/e1_streams

message(paste("Therefore, Goodmann and Kruskals Lambda is: ", lambda))

library("ryouready")

nom.lambda(tab2)

```


Analysis of variance

```{r}

table(x$Genre)

wilcox.test(x$Streams[x$Genre == 'Hip Hop'], x$Streams[x$Genre == 'Pop'])
t.test(x$Streams[x$Genre == 'Hip Hop'], x$Streams[x$Genre == 'Pop'])

fit <- aov(Streams~Genre , data =x)
summary(fit)


```

Additional plots

```{r}
plot(table(x$Genre, x$stream_quantile_ind))

plot(table(x$stream_quantile_ind, x$viewsCount_quantile_ind, x$Follower_median_ind))

require("MASS")
require("dplyr")

exclude.cols <- c('stream_quantile_ind', 'viewsCount_quantile_ind', 'Follower_median_ind')

no_nas <- numeric_cor_x[complete.cases(numeric_cor_x), ]

clean_coord <- dplyr::select(no_nas, -one_of(exclude.cols))

parcoord(clean_coord, var.label = TRUE)

library("lattice")
parallelplot(clean_coord, horizontal.axis=T)

library("ggplot2")
library("GGally")
ggparcoord(clean_coord) + geom_line()

library("andrews")
andrews(clean_coord, ymax=4)

# x_clean <- x[complete.cases(x), ]

col_genre <- ifelse(x$Genre == 'Hip Hop', "black", "red")


keep.cols <- c('Streams', 'Artist_Follower', 'viewsCount', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence')

col_df <- dplyr::select(x_clean, keep.cols)
log_col_df <- log(col_df)

pairs(log_col_df, cex=0.5, col=col_genre)

parcoord(clean_coord, col=col_genre)

ax <- clean_coord
ax$clr <- as.numeric(ifelse(col_genre == 'black', 1, 0))
andrews(ax, ymax=4, clr=34)

```


Scagnostics

```{r}

library("scagnostics")

s <- scagnostics(numeric_cor_x)
o <- scagnosticsOutliers(s)
g <- scagnosticsGrid(s)

go <- g[o,] # x, y return columns of outlying feature pairs

#plots <- apply(s==max(s), 2, any)
#gps <- g[plots,]
#for (i in 1:nrow(gps)) {
#xi <- gps$x[i]
#yi <- gps$y[i]
#plot(numeric_cor_x[,xi], numeric_cor_x[,yi],
#xlab=names(numeric_cor_x)[xi], ylab=names(numeric_cor_x)[yi])
#}

#scagnostics_cols <- c("Title_Google_searches_11m", "Title_Artist_Google_searches_11m", "stream_quantile_ind", #"Artist_Albums_Number", "Artist_Popularity", "viewsCount_quantile_ind", "viewsCount", "Follower_median_ind", #"Artist_Albums_Tracks_Number")


# Outliers: strongly different from the other plots

for (i in 1:nrow(go)){

    plot(numeric_cor_x[[go[i,1]]], numeric_cor_x[[go[i,2]]], pch=19,
     xlab=names(numeric_cor_x)[go[i,1]], ylab=names(numeric_cor_x)[go[i,2]])}

# Exemplars: group of similar plots

e <- scagnosticsExemplars(s)

ge <- g[e,]

par(mfrow = c(2,2))

for (i in 1:dim(ge)[1]){
plot(numeric_cor_x[[ge$x[i]]], numeric_cor_x[[ge$y[i]]], pch=19,
xlab=names(numeric_cor_x)[ge$x[i]], ylab=names(numeric_cor_x)[ge$y[i]])
}

```

```{r}

# pc_cov <- prcomp(numeric_cor_x[23:32])

unselect_col <- c('dislikeCount', 'likeCount')

dplyr::select(numeric_cor_x, -one_of(unselect_col))

pc_cov <- prcomp(dplyr::select(numeric_cor_x, -one_of(unselect_col)))

# pc_cov <- prcomp(numeric_cor_x[1:28])

par(mfrow=c(1,2))
plot(pc_cov, main="Scree plot as bar chart (cov)")
plot(pc_cov$sdev^2, type="b", main="Scree plot (cov)")

pc_cor <- prcomp(dplyr::select(numeric_cor_x, -one_of(unselect_col)), center=T, scale=T)
plot(pc_cor$sdev^2, type="b", main="Scree plot (cor)")

library("psych")
ppc<-principal(dplyr::select(numeric_cor_x, -one_of(unselect_col)), rotate="none")
ppc
scree(dplyr::select(numeric_cor_x, -one_of(unselect_col)))

par(mfrow=c(1,2))

biplot(pc_cov)
biplot(pc_cor)

pc_cor_pred <- predict(pc_cor)
plot(pc_cor_pred[, 1:2], col = col_genre)
plot(pc_cor_pred[, 1:2], type = "n", xlab = "PC1", ylab = "PC2")
text(pc_cor_pred[, 1:2], as.character(x$Genre))

```





```{r}
library("dplyr")

model1 <- lm(Track_Popularity ~ ., data = numeric_x)

#print(model1)
#summary(model1)

#for (coef_index in 1:length(model1$coefficients)){
  
#  message(paste(names(model1$coefficients)[coef_index] ,': ' ,model1$coefficients[coef_index]))
  
#}

summary(model1)$r.squared

unselect_col <- c("Artist_Popularity")

model2 <- lm(Track_Popularity ~ ., data = dplyr::select(numeric_x, -one_of(unselect_col)))

summary(model2)$r.squared

#print(model2)
#summary(model2)

for (coef_index in 1:length(model2$coefficients)){
  
  message(paste(names(model2$coefficients)[coef_index] ,': ' ,model2$coefficients[coef_index]))
  
}





```

